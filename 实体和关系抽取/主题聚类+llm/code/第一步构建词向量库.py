import os
import json
import torch
from transformers import AutoTokenizer, AutoModel
from tqdm import tqdm

# =============================
# è®¾ç½®æ¨¡å‹ï¼ˆbge-large-zh-v1.5ï¼‰
# =============================
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model_name = "BAAI/bge-large-zh-v1.5"

print("ğŸ”„ æ­£åœ¨åŠ è½½æ¨¡å‹ï¼Œè¯·ç¨å€™...")
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModel.from_pretrained(model_name).to(device).eval()
print("âœ… æ¨¡å‹åŠ è½½å®Œæˆï¼")

# =============================
# åµŒå…¥å‡½æ•°ï¼ˆå– CLS å‘é‡ï¼‰
# =============================
def embed_text(text: str):
    try:
        # bgeæ¨¡å‹å»ºè®®åœ¨æ–‡æœ¬å‰æ·»åŠ  "[CLS]" ä»¥æå‡æ•ˆæœ
        text = "[CLS] " + text
        inputs = tokenizer(text, return_tensors="pt", truncation=True, max_length=512).to(device)
        with torch.no_grad():
            outputs = model(**inputs)
        # CLS token è¡¨å¾
        embedding = outputs.last_hidden_state[:, 0].squeeze().cpu().numpy()
        return embedding.tolist()
    except Exception as e:
        print(f"[âš ï¸ é”™è¯¯] åµŒå…¥å¤±è´¥ï¼š{e}")
        return None

# =============================
# ä¸»å¤„ç†å‡½æ•°
# =============================
def process_markdown_files(md_folder: str, output_path: str):
    all_embeddings = []
    md_files = [f for f in os.listdir(md_folder) if f.endswith(".md")]
    
    for filename in tqdm(md_files, desc="ğŸ“„ æ­£åœ¨å¤„ç†æ–‡æ¡£"):
        filepath = os.path.join(md_folder, filename)
        try:
            with open(filepath, "r", encoding="utf-8") as f:
                content = f.read()
            
            # æŒ‰æ®µè½åˆ‡åˆ†ï¼ˆä»¥ç©ºè¡Œä¸ºæ®µè½åˆ†ç•Œï¼‰
            paragraphs = [p.strip() for p in content.split("\n\n") if len(p.strip()) > 10]
            for idx, para in enumerate(paragraphs):
                vector = embed_text(para)
                if vector:
                    all_embeddings.append({
                        "file": filename,
                        "paragraph_index": idx,
                        "text": para,
                        "embedding": vector
                    })
        except Exception as e:
            print(f"[âš ï¸ é”™è¯¯] æ— æ³•å¤„ç† {filename}ï¼š{e}")

    # ä¿å­˜
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(all_embeddings, f, indent=2, ensure_ascii=False)
    print(f"âœ… å‘é‡åº“å·²ä¿å­˜åˆ°ï¼š{output_path}")

# =============================
# æ‰§è¡Œä¸»ç¨‹åº
# =============================
if __name__ == "__main__":
    input_folder = "è‡ªæˆ‘æ ‡æ³¨æ•°æ®"
    output_file = "æ•°æ®ç»“æœ/embedding_vectors.json"
    process_markdown_files(input_folder, output_file)
